{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09033d7",
   "metadata": {},
   "source": [
    "# Importing Libraries and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55b1c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    print(\"NLTK resources downloaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK resources: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfe407b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully Shape: (31014, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentiment_data.csv\")\n",
    "print(f\"Data loaded successfully Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2f32b",
   "metadata": {},
   "source": [
    "## Analzying the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5ba3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "  Time of Tweet Age of User      Country  \n",
       "0       morning        0-20  Afghanistan  \n",
       "1          noon       21-30      Albania  \n",
       "2         night       31-45      Algeria  \n",
       "3       morning       46-60      Andorra  \n",
       "4          noon       60-70       Angola  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows and column info to check structure\n",
    "print(\"First 5 Rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa0f7036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f90c6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31014 entries, 0 to 31013\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         31014 non-null  object\n",
      " 1   text           31014 non-null  object\n",
      " 2   sentiment      31014 non-null  object\n",
      " 3   Time of Tweet  31014 non-null  object\n",
      " 4   Age of User    31014 non-null  object\n",
      " 5   Country        31014 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Column Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aca265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values check:\n",
      "textID           0\n",
      "text             0\n",
      "sentiment        0\n",
      "Time of Tweet    0\n",
      "Age of User      0\n",
      "Country          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for Missing Values (Nulls)\n",
    "print(\"Missing values check:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14681e88",
   "metadata": {},
   "source": [
    "# PreProcessing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e8c1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before removing duplicates: 31014\n",
      "Total rows after removing duplicates: 31014\n"
     ]
    }
   ],
   "source": [
    "#Handling Potential Duplicates\n",
    "print(f\"Total rows before removing duplicates: {df.shape[0]}\")\n",
    "df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "print(f\"Total rows after removing duplicates: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b5add88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing global NLP objects\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "065f82a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete. Added 'clean_text' column.\n",
      "\n",
      "Sample of Cleaned Data:\n",
      "                                                text  \\\n",
      "0  Last session of the day  http://twitpic.com/67ezh   \n",
      "1   Shanghai is also really exciting (precisely -...   \n",
      "2  Recession hit Veronique Branquinho, she has to...   \n",
      "3                                        happy bday!   \n",
      "4             http://twitpic.com/4w75p - I like it!!   \n",
      "\n",
      "                                          clean_text sentiment  \n",
      "0                                   last session day   neutral  \n",
      "1  shanghai also really exciting precisely skyscr...  positive  \n",
      "2  recession hit veronique branquinho quit compan...  negative  \n",
      "3                                         happy bday  positive  \n",
      "4                                               like  positive  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(token)\n",
    "        for token in tokens\n",
    "        if token.isalpha() and token not in stop_words\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Data cleaning complete. Added 'clean_text' column.\")\n",
    "print(\"\\nSample of Cleaned Data:\")\n",
    "print(df[['text', 'clean_text', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b60ed5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             0\n",
       "sentiment        0\n",
       "Time of Tweet    0\n",
       "Age of User      0\n",
       "Country          0\n",
       "clean_text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e77f16",
   "metadata": {},
   "source": [
    "# Model Training of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fc2cff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 24811 samples\n",
      "Testing set size: 6203 samples\n"
     ]
    }
   ],
   "source": [
    "X = df['clean_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b6a96",
   "metadata": {},
   "source": [
    "## Using Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features created. Training matrix shape: (24811, 50000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorization: Fitting TfidfVectorizer on training data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=50000, ngram_range=(1, 2))\n",
    "\n",
    "# Fitting and transforming the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transforming the test data using the fitted vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF features created. Training matrix shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cbc3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakshita Chawla\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Training Complete.\n"
     ]
    }
   ],
   "source": [
    "#Model Training: Logistic Regression\n",
    "sentiment_model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model on the TF-IDF features\n",
    "sentiment_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Logistic Regression Model Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5193f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.59      0.65      1756\n",
      "     neutral       0.65      0.76      0.70      2510\n",
      "    positive       0.78      0.75      0.76      1937\n",
      "\n",
      "    accuracy                           0.71      6203\n",
      "   macro avg       0.72      0.70      0.70      6203\n",
      "weighted avg       0.71      0.71      0.71      6203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "y_pred = sentiment_model.predict(X_test_tfidf)\n",
    "\n",
    "# Displaying the Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a93c33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer saved to tfidf_vectorizer.joblib\n",
      "LogisticRegression Model saved to sentiment_model.joblib\n",
      "All files are saved and ready for analysis on real time data\n"
     ]
    }
   ],
   "source": [
    "# Saving the vectorizer and model\n",
    "vectorizer_path = 'tfidf_vectorizer.joblib'\n",
    "model_path = 'sentiment_model.joblib'\n",
    "\n",
    "# Saving the TfidfVectorizer\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "print(f\"TfidfVectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "# Saving the LogisticRegression Model\n",
    "joblib.dump(sentiment_model, model_path)\n",
    "print(f\"LogisticRegression Model saved to {model_path}\")\n",
    "\n",
    "print(\"All files are saved and ready for analysis on real time data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
